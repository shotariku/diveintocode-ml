{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】コードレビュー"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下記コードで画像データをndarrayにしてResNetのデフォルトのinputサイズの(224, 224)にresizeしてkfoldでtrainデータとvalidationデータに分割している\n",
    "```python\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下記コードでiouを求めている\n",
    "```python\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下記コードでkerasのresnet50をモデルとして使う。include_top=Falseとすることで全結合層を除く。\n",
    "```python\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model.summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下記コードでデコーダーのcontracting pathと結合する前の各ブロックを作成している。\n",
    "```python\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下記コードでエンコーダとしてresnet50を使用したu-netを作成している。エンコーダーの中のダウンサンプリングする直前の層をデコーダーにconcatenateしている。\n",
    "```python\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('conv1').output # activation_1\n",
    "    encoder2 = base_model.get_layer('res2c_branch2c').output # activation_10\n",
    "    encoder3 = base_model.get_layer('res3d_branch2c').output # activation_22\n",
    "    encoder4 = base_model.get_layer('res4f_branch2c').output # activation_40\n",
    "    encoder5 = base_model.get_layer('res5c_branch2c').output # activation_40\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下記コードでimagenetで学習した重みを初期値として使って今回のデータの学習をしている\n",
    "```python\n",
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_resnet(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 2  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下記コードでoutputを(101, 101)のサイズに戻している。\n",
    "```python\n",
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】学習・推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNetの学習・推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture tuning & score optimization\n",
    "\n",
    "\n",
    "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
    "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:39.259864Z",
     "start_time": "2020-03-25T14:39:39.039884Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:43.879310Z",
     "start_time": "2020-03-25T14:39:43.876304Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:44.446808Z",
     "start_time": "2020-03-25T14:39:44.431975Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:47.676622Z",
     "start_time": "2020-03-25T14:39:47.485724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('sample_submission.csv')\n",
    "depth = pd.read_csv('depths.csv')\n",
    "\n",
    "train_src = 'train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:58.581787Z",
     "start_time": "2020-03-25T14:39:50.781893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:59.083122Z",
     "start_time": "2020-03-25T14:39:58.584544Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e179a29548>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:08.034054Z",
     "start_time": "2020-03-25T14:40:07.987000Z"
    }
   },
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:35.924796Z",
     "start_time": "2020-03-25T14:40:09.595933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
      "(804, 224, 224, 3) (804, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:35.952868Z",
     "start_time": "2020-03-25T14:40:35.927679Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder features - ResNet50:\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
    "Default input size will be assumed, which is (224, 224, 3).\n",
    "Layers will be as follows:\n",
    "\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:43.034360Z",
     "start_time": "2020-03-25T14:40:35.954603Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - ETA:  - ETA: 10:4 - ETA: 9:3 - ETA: 5: - ETA: 6: - ETA: 4: - ETA: 3: - ETA: 3: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 1: - ETA: 2: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 59s - ETA: 59 - ETA: 57 - ETA: 57 - ETA: 56 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 51 - ETA: 50 - ETA: 50 - ETA: 49 - ETA: 48 - ETA: 48 - ETA: 47 - ETA: 46 - ETA: 46 - ETA: 45 - ETA: 44 - ETA: 44 - ETA: 43 - ETA: 42 - ETA: 42 - ETA: 41 - ETA: 41 - ETA: 40 - ETA: 40 - ETA: 39 - ETA: 39 - ETA: 38 - ETA: 38 - ETA: 37 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 35 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 34 - ETA: 32 - ETA: 32 - ETA: 31 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 23 - ETA: 24 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 27s 0us/step\n",
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder blocks:\n",
    "\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
    "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:46.197121Z",
     "start_time": "2020-03-25T14:40:46.188335Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition:\n",
    "\n",
    "Combine encoder and decoder blocks to create final segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:54:51.684488Z",
     "start_time": "2020-03-25T14:54:51.673231Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('conv1').output # activation_1\n",
    "    encoder2 = base_model.get_layer('res2c_branch2c').output # activation_10\n",
    "    encoder3 = base_model.get_layer('res3d_branch2c').output # activation_22\n",
    "    encoder4 = base_model.get_layer('res4f_branch2c').output # activation_40\n",
    "    encoder5 = base_model.get_layer('res5c_branch2c').output # activation_40\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:55:00.601042Z",
     "start_time": "2020-03-25T14:54:53.772115Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
      "                                                                 res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 42,903,873\n",
      "Trainable params: 42,852,737\n",
      "Non-trainable params: 51,136\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_resnet(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T17:37:03.773696Z",
     "start_time": "2020-03-25T14:58:43.483800Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
      "                                                                 res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 48,970,161\n",
      "Trainable params: 48,915,857\n",
      "Non-trainable params: 54,304\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 3196 samples, validate on 804 samples\n",
      "Epoch 1/2\n",
      "2512/3196 [======================>.......] - ETA: 3:29:20 - loss: 1.5334 - my_iou_metric: 0.0000e+ - ETA: 3:18:00 - loss: 1.4392 - my_iou_metric: 0.0250   - ETA: 3:35:40 - loss: 1.3904 - my_iou_metric: 0.04 - ETA: 3:40:12 - loss: 1.4377 - my_iou_metric: 0.03 - ETA: 3:32:43 - loss: 1.4271 - my_iou_metric: 0.04 - ETA: 3:32:12 - loss: 1.3628 - my_iou_metric: 0.05 - ETA: 3:36:59 - loss: 1.3420 - my_iou_metric: 0.06 - ETA: 3:44:34 - loss: 1.2957 - my_iou_metric: 0.06 - ETA: 4:02:55 - loss: 1.2516 - my_iou_metric: 0.07 - ETA: 4:16:01 - loss: 1.1963 - my_iou_metric: 0.09 - ETA: 4:14:38 - loss: 1.1867 - my_iou_metric: 0.09 - ETA: 4:11:09 - loss: 1.1612 - my_iou_metric: 0.09 - ETA: 4:09:47 - loss: 1.1559 - my_iou_metric: 0.10 - ETA: 4:06:58 - loss: 1.1068 - my_iou_metric: 0.11 - ETA: 4:04:43 - loss: 1.1087 - my_iou_metric: 0.11 - ETA: 4:05:41 - loss: 1.0990 - my_iou_metric: 0.11 - ETA: 4:03:35 - loss: 1.0973 - my_iou_metric: 0.11 - ETA: 4:01:39 - loss: 1.0799 - my_iou_metric: 0.12 - ETA: 3:59:50 - loss: 1.0676 - my_iou_metric: 0.12 - ETA: 3:57:48 - loss: 1.0778 - my_iou_metric: 0.13 - ETA: 3:56:09 - loss: 1.0772 - my_iou_metric: 0.14 - ETA: 3:54:11 - loss: 1.0662 - my_iou_metric: 0.14 - ETA: 3:53:18 - loss: 1.0604 - my_iou_metric: 0.14 - ETA: 3:52:48 - loss: 1.0437 - my_iou_metric: 0.15 - ETA: 3:52:00 - loss: 1.0480 - my_iou_metric: 0.14 - ETA: 3:50:12 - loss: 1.0414 - my_iou_metric: 0.14 - ETA: 3:49:05 - loss: 1.0314 - my_iou_metric: 0.15 - ETA: 3:45:42 - loss: 1.0277 - my_iou_metric: 0.14 - ETA: 3:41:20 - loss: 1.0135 - my_iou_metric: 0.15 - ETA: 3:37:33 - loss: 1.0161 - my_iou_metric: 0.15 - ETA: 3:34:25 - loss: 1.0129 - my_iou_metric: 0.15 - ETA: 3:32:01 - loss: 1.0067 - my_iou_metric: 0.15 - ETA: 3:29:36 - loss: 1.0080 - my_iou_metric: 0.16 - ETA: 3:25:44 - loss: 1.0008 - my_iou_metric: 0.17 - ETA: 3:21:39 - loss: 0.9890 - my_iou_metric: 0.17 - ETA: 3:17:50 - loss: 0.9763 - my_iou_metric: 0.18 - ETA: 3:14:08 - loss: 0.9734 - my_iou_metric: 0.18 - ETA: 3:10:38 - loss: 0.9616 - my_iou_metric: 0.18 - ETA: 3:07:13 - loss: 0.9543 - my_iou_metric: 0.19 - ETA: 3:04:07 - loss: 0.9494 - my_iou_metric: 0.19 - ETA: 3:01:47 - loss: 0.9473 - my_iou_metric: 0.19 - ETA: 3:00:17 - loss: 0.9522 - my_iou_metric: 0.19 - ETA: 2:58:06 - loss: 0.9556 - my_iou_metric: 0.19 - ETA: 2:55:49 - loss: 0.9558 - my_iou_metric: 0.19 - ETA: 2:53:36 - loss: 0.9496 - my_iou_metric: 0.20 - ETA: 2:51:26 - loss: 0.9480 - my_iou_metric: 0.19 - ETA: 2:49:21 - loss: 0.9515 - my_iou_metric: 0.20 - ETA: 2:47:13 - loss: 0.9463 - my_iou_metric: 0.20 - ETA: 2:45:17 - loss: 0.9420 - my_iou_metric: 0.20 - ETA: 2:43:16 - loss: 0.9325 - my_iou_metric: 0.20 - ETA: 2:41:15 - loss: 0.9272 - my_iou_metric: 0.20 - ETA: 2:39:23 - loss: 0.9281 - my_iou_metric: 0.20 - ETA: 2:37:32 - loss: 0.9207 - my_iou_metric: 0.20 - ETA: 2:35:39 - loss: 0.9203 - my_iou_metric: 0.21 - ETA: 2:33:51 - loss: 0.9133 - my_iou_metric: 0.21 - ETA: 2:32:04 - loss: 0.9118 - my_iou_metric: 0.21 - ETA: 2:30:21 - loss: 0.9094 - my_iou_metric: 0.21 - ETA: 2:28:41 - loss: 0.9052 - my_iou_metric: 0.21 - ETA: 2:27:06 - loss: 0.8969 - my_iou_metric: 0.22 - ETA: 2:25:32 - loss: 0.8895 - my_iou_metric: 0.22 - ETA: 2:24:01 - loss: 0.8853 - my_iou_metric: 0.22 - ETA: 2:22:29 - loss: 0.8811 - my_iou_metric: 0.23 - ETA: 2:20:55 - loss: 0.8857 - my_iou_metric: 0.23 - ETA: 2:19:27 - loss: 0.8775 - my_iou_metric: 0.23 - ETA: 2:17:56 - loss: 0.8868 - my_iou_metric: 0.23 - ETA: 2:16:26 - loss: 0.8883 - my_iou_metric: 0.24 - ETA: 2:15:02 - loss: 0.8840 - my_iou_metric: 0.24 - ETA: 2:13:33 - loss: 0.8846 - my_iou_metric: 0.24 - ETA: 2:12:12 - loss: 0.8878 - my_iou_metric: 0.24 - ETA: 2:11:01 - loss: 0.8855 - my_iou_metric: 0.25 - ETA: 2:09:57 - loss: 0.8829 - my_iou_metric: 0.25 - ETA: 2:08:50 - loss: 0.8802 - my_iou_metric: 0.25 - ETA: 2:07:49 - loss: 0.8816 - my_iou_metric: 0.25 - ETA: 2:06:49 - loss: 0.8820 - my_iou_metric: 0.25 - ETA: 2:05:48 - loss: 0.8842 - my_iou_metric: 0.25 - ETA: 2:04:53 - loss: 0.8852 - my_iou_metric: 0.25 - ETA: 2:04:29 - loss: 0.8829 - my_iou_metric: 0.25 - ETA: 2:03:55 - loss: 0.8820 - my_iou_metric: 0.25 - ETA: 2:02:48 - loss: 0.8816 - my_iou_metric: 0.25 - ETA: 2:01:46 - loss: 0.8809 - my_iou_metric: 0.26 - ETA: 2:00:45 - loss: 0.8787 - my_iou_metric: 0.26 - ETA: 1:59:37 - loss: 0.8739 - my_iou_metric: 0.26 - ETA: 1:58:29 - loss: 0.8705 - my_iou_metric: 0.26 - ETA: 1:57:20 - loss: 0.8715 - my_iou_metric: 0.26 - ETA: 1:56:17 - loss: 0.8727 - my_iou_metric: 0.26 - ETA: 1:55:17 - loss: 0.8689 - my_iou_metric: 0.26 - ETA: 1:54:23 - loss: 0.8697 - my_iou_metric: 0.26 - ETA: 1:53:27 - loss: 0.8704 - my_iou_metric: 0.26 - ETA: 1:52:40 - loss: 0.8662 - my_iou_metric: 0.27 - ETA: 1:51:56 - loss: 0.8634 - my_iou_metric: 0.27 - ETA: 1:51:09 - loss: 0.8614 - my_iou_metric: 0.27 - ETA: 1:50:10 - loss: 0.8577 - my_iou_metric: 0.27 - ETA: 1:49:16 - loss: 0.8610 - my_iou_metric: 0.27 - ETA: 1:48:19 - loss: 0.8580 - my_iou_metric: 0.27 - ETA: 1:47:23 - loss: 0.8543 - my_iou_metric: 0.27 - ETA: 1:46:33 - loss: 0.8520 - my_iou_metric: 0.27 - ETA: 1:46:22 - loss: 0.8479 - my_iou_metric: 0.27 - ETA: 1:45:39 - loss: 0.8462 - my_iou_metric: 0.27 - ETA: 1:44:34 - loss: 0.8486 - my_iou_metric: 0.27 - ETA: 1:43:21 - loss: 0.8456 - my_iou_metric: 0.27 - ETA: 1:42:09 - loss: 0.8432 - my_iou_metric: 0.27 - ETA: 1:41:15 - loss: 0.8422 - my_iou_metric: 0.27 - ETA: 1:40:51 - loss: 0.8381 - my_iou_metric: 0.27 - ETA: 1:40:31 - loss: 0.8357 - my_iou_metric: 0.27 - ETA: 1:39:41 - loss: 0.8347 - my_iou_metric: 0.27 - ETA: 1:38:45 - loss: 0.8363 - my_iou_metric: 0.27 - ETA: 1:38:04 - loss: 0.8319 - my_iou_metric: 0.28 - ETA: 1:37:24 - loss: 0.8353 - my_iou_metric: 0.28 - ETA: 1:36:50 - loss: 0.8329 - my_iou_metric: 0.28 - ETA: 1:35:58 - loss: 0.8318 - my_iou_metric: 0.28 - ETA: 1:34:51 - loss: 0.8286 - my_iou_metric: 0.28 - ETA: 1:33:41 - loss: 0.8320 - my_iou_metric: 0.28 - ETA: 1:32:29 - loss: 0.8342 - my_iou_metric: 0.28 - ETA: 1:31:19 - loss: 0.8314 - my_iou_metric: 0.29 - ETA: 1:30:02 - loss: 0.8322 - my_iou_metric: 0.29 - ETA: 1:28:40 - loss: 0.8331 - my_iou_metric: 0.29 - ETA: 1:27:22 - loss: 0.8318 - my_iou_metric: 0.29 - ETA: 1:26:16 - loss: 0.8327 - my_iou_metric: 0.29 - ETA: 1:25:28 - loss: 0.8379 - my_iou_metric: 0.29 - ETA: 1:24:39 - loss: 0.8356 - my_iou_metric: 0.29 - ETA: 1:23:36 - loss: 0.8365 - my_iou_metric: 0.29 - ETA: 1:22:33 - loss: 0.8378 - my_iou_metric: 0.29 - ETA: 1:21:42 - loss: 0.8349 - my_iou_metric: 0.29 - ETA: 1:20:46 - loss: 0.8355 - my_iou_metric: 0.29 - ETA: 1:19:47 - loss: 0.8332 - my_iou_metric: 0.29 - ETA: 1:18:55 - loss: 0.8336 - my_iou_metric: 0.29 - ETA: 1:18:04 - loss: 0.8341 - my_iou_metric: 0.29 - ETA: 1:17:18 - loss: 0.8345 - my_iou_metric: 0.29 - ETA: 1:16:29 - loss: 0.8353 - my_iou_metric: 0.29 - ETA: 1:15:40 - loss: 0.8333 - my_iou_metric: 0.29 - ETA: 1:14:51 - loss: 0.8328 - my_iou_metric: 0.29 - ETA: 1:14:01 - loss: 0.8331 - my_iou_metric: 0.29 - ETA: 1:13:21 - loss: 0.8324 - my_iou_metric: 0.29 - ETA: 1:12:41 - loss: 0.8294 - my_iou_metric: 0.29 - ETA: 1:11:49 - loss: 0.8260 - my_iou_metric: 0.29 - ETA: 1:10:56 - loss: 0.8258 - my_iou_metric: 0.29 - ETA: 1:10:06 - loss: 0.8262 - my_iou_metric: 0.29 - ETA: 1:09:11 - loss: 0.8253 - my_iou_metric: 0.29 - ETA: 1:08:17 - loss: 0.8257 - my_iou_metric: 0.29 - ETA: 1:07:21 - loss: 0.8224 - my_iou_metric: 0.29 - ETA: 1:06:31 - loss: 0.8228 - my_iou_metric: 0.30 - ETA: 1:05:50 - loss: 0.8216 - my_iou_metric: 0.30 - ETA: 1:05:01 - loss: 0.8202 - my_iou_metric: 0.30 - ETA: 1:04:09 - loss: 0.8185 - my_iou_metric: 0.30 - ETA: 1:03:02 - loss: 0.8187 - my_iou_metric: 0.30 - ETA: 1:01:55 - loss: 0.8153 - my_iou_metric: 0.30 - ETA: 1:00:49 - loss: 0.8135 - my_iou_metric: 0.30 - ETA: 59:42 - loss: 0.8122 - my_iou_metric: 0.3050 - ETA: 58:35 - loss: 0.8098 - my_iou_metric: 0.30 - ETA: 57:27 - loss: 0.8122 - my_iou_metric: 0.30 - ETA: 56:14 - loss: 0.8116 - my_iou_metric: 0.30 - ETA: 54:59 - loss: 0.8126 - my_iou_metric: 0.30 - ETA: 53:44 - loss: 0.8128 - my_iou_metric: 0.30 - ETA: 52:31 - loss: 0.8103 - my_iou_metric: 0.30 - ETA: 51:18 - loss: 0.8099 - my_iou_metric: 0.30 - ETA: 50:12 - loss: 0.8096 - my_iou_metric: 0.30 - ETA: 49:08 - loss: 0.8081 - my_iou_metric: 0.30953196/3196 [==============================] - ETA: 48:01 - loss: 0.8067 - my_iou_metric: 0.31 - ETA: 46:48 - loss: 0.8079 - my_iou_metric: 0.30 - ETA: 45:35 - loss: 0.8060 - my_iou_metric: 0.30 - ETA: 44:25 - loss: 0.8056 - my_iou_metric: 0.30 - ETA: 43:16 - loss: 0.8049 - my_iou_metric: 0.30 - ETA: 42:09 - loss: 0.8037 - my_iou_metric: 0.30 - ETA: 41:05 - loss: 0.8028 - my_iou_metric: 0.30 - ETA: 40:01 - loss: 0.8017 - my_iou_metric: 0.31 - ETA: 38:55 - loss: 0.7995 - my_iou_metric: 0.31 - ETA: 37:46 - loss: 0.7987 - my_iou_metric: 0.31 - ETA: 36:35 - loss: 0.7974 - my_iou_metric: 0.31 - ETA: 35:24 - loss: 0.7953 - my_iou_metric: 0.31 - ETA: 34:16 - loss: 0.7933 - my_iou_metric: 0.31 - ETA: 33:08 - loss: 0.7931 - my_iou_metric: 0.31 - ETA: 31:58 - loss: 0.7920 - my_iou_metric: 0.31 - ETA: 30:47 - loss: 0.7892 - my_iou_metric: 0.32 - ETA: 29:35 - loss: 0.7902 - my_iou_metric: 0.32 - ETA: 28:26 - loss: 0.7885 - my_iou_metric: 0.32 - ETA: 27:16 - loss: 0.7875 - my_iou_metric: 0.32 - ETA: 26:05 - loss: 0.7869 - my_iou_metric: 0.32 - ETA: 24:56 - loss: 0.7847 - my_iou_metric: 0.32 - ETA: 23:46 - loss: 0.7850 - my_iou_metric: 0.32 - ETA: 22:36 - loss: 0.7842 - my_iou_metric: 0.32 - ETA: 21:26 - loss: 0.7831 - my_iou_metric: 0.32 - ETA: 20:17 - loss: 0.7833 - my_iou_metric: 0.33 - ETA: 19:07 - loss: 0.7820 - my_iou_metric: 0.33 - ETA: 17:59 - loss: 0.7804 - my_iou_metric: 0.33 - ETA: 16:51 - loss: 0.7810 - my_iou_metric: 0.33 - ETA: 15:44 - loss: 0.7800 - my_iou_metric: 0.33 - ETA: 14:35 - loss: 0.7788 - my_iou_metric: 0.33 - ETA: 13:25 - loss: 0.7769 - my_iou_metric: 0.33 - ETA: 12:16 - loss: 0.7772 - my_iou_metric: 0.33 - ETA: 11:07 - loss: 0.7775 - my_iou_metric: 0.33 - ETA: 9:58 - loss: 0.7759 - my_iou_metric: 0.3332 - ETA: 8:49 - loss: 0.7761 - my_iou_metric: 0.332 - ETA: 7:41 - loss: 0.7773 - my_iou_metric: 0.331 - ETA: 6:32 - loss: 0.7765 - my_iou_metric: 0.332 - ETA: 5:23 - loss: 0.7751 - my_iou_metric: 0.332 - ETA: 4:15 - loss: 0.7747 - my_iou_metric: 0.332 - ETA: 3:07 - loss: 0.7727 - my_iou_metric: 0.332 - ETA: 1:58 - loss: 0.7730 - my_iou_metric: 0.333 - ETA: 50s - loss: 0.7720 - my_iou_metric: 0.333 - 14740s 5s/step - loss: 0.7724 - my_iou_metric: 0.3333 - val_loss: 2562.0412 - val_my_iou_metric: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.00000, saving model to unet_resnet.h5\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2528/3196 [======================>.......] - ETA: 3:24:59 - loss: 0.6050 - my_iou_metric: 0.58 - ETA: 3:30:33 - loss: 0.5352 - my_iou_metric: 0.50 - ETA: 3:32:39 - loss: 0.5506 - my_iou_metric: 0.47 - ETA: 3:49:29 - loss: 0.5593 - my_iou_metric: 0.41 - ETA: 3:54:06 - loss: 0.5709 - my_iou_metric: 0.42 - ETA: 3:50:27 - loss: 0.5485 - my_iou_metric: 0.43 - ETA: 3:43:48 - loss: 0.5553 - my_iou_metric: 0.43 - ETA: 3:40:44 - loss: 0.5469 - my_iou_metric: 0.42 - ETA: 3:35:34 - loss: 0.5638 - my_iou_metric: 0.42 - ETA: 3:33:43 - loss: 0.5404 - my_iou_metric: 0.43 - ETA: 3:29:24 - loss: 0.5259 - my_iou_metric: 0.44 - ETA: 3:25:38 - loss: 0.5299 - my_iou_metric: 0.46 - ETA: 3:21:38 - loss: 0.5255 - my_iou_metric: 0.47 - ETA: 3:18:23 - loss: 0.5575 - my_iou_metric: 0.46 - ETA: 3:15:41 - loss: 0.5837 - my_iou_metric: 0.45 - ETA: 3:13:40 - loss: 0.5840 - my_iou_metric: 0.46 - ETA: 3:12:26 - loss: 0.5740 - my_iou_metric: 0.46 - ETA: 3:10:06 - loss: 0.5627 - my_iou_metric: 0.47 - ETA: 3:08:35 - loss: 0.5637 - my_iou_metric: 0.47 - ETA: 3:07:11 - loss: 0.5778 - my_iou_metric: 0.47 - ETA: 3:05:24 - loss: 0.5748 - my_iou_metric: 0.46 - ETA: 3:03:53 - loss: 0.5795 - my_iou_metric: 0.46 - ETA: 3:02:07 - loss: 0.5883 - my_iou_metric: 0.47 - ETA: 3:00:32 - loss: 0.5821 - my_iou_metric: 0.47 - ETA: 2:58:54 - loss: 0.5927 - my_iou_metric: 0.47 - ETA: 2:56:51 - loss: 0.5968 - my_iou_metric: 0.47 - ETA: 2:56:18 - loss: 0.6028 - my_iou_metric: 0.46 - ETA: 2:55:02 - loss: 0.6205 - my_iou_metric: 0.46 - ETA: 2:53:43 - loss: 0.6112 - my_iou_metric: 0.45 - ETA: 2:53:36 - loss: 0.6026 - my_iou_metric: 0.46 - ETA: 2:52:44 - loss: 0.6017 - my_iou_metric: 0.47 - ETA: 2:52:36 - loss: 0.6064 - my_iou_metric: 0.47 - ETA: 2:52:17 - loss: 0.6193 - my_iou_metric: 0.46 - ETA: 2:51:40 - loss: 0.6197 - my_iou_metric: 0.45 - ETA: 2:50:46 - loss: 0.6238 - my_iou_metric: 0.45 - ETA: 2:49:55 - loss: 0.6243 - my_iou_metric: 0.45 - ETA: 2:48:41 - loss: 0.6232 - my_iou_metric: 0.45 - ETA: 2:48:34 - loss: 0.6288 - my_iou_metric: 0.45 - ETA: 2:47:29 - loss: 0.6334 - my_iou_metric: 0.45 - ETA: 2:46:12 - loss: 0.6321 - my_iou_metric: 0.45 - ETA: 2:44:55 - loss: 0.6267 - my_iou_metric: 0.45 - ETA: 2:43:39 - loss: 0.6237 - my_iou_metric: 0.44 - ETA: 2:44:58 - loss: 0.6259 - my_iou_metric: 0.44 - ETA: 2:46:13 - loss: 0.6258 - my_iou_metric: 0.44 - ETA: 2:45:38 - loss: 0.6218 - my_iou_metric: 0.45 - ETA: 2:44:49 - loss: 0.6201 - my_iou_metric: 0.44 - ETA: 2:44:30 - loss: 0.6204 - my_iou_metric: 0.45 - ETA: 2:45:16 - loss: 0.6185 - my_iou_metric: 0.45 - ETA: 2:45:32 - loss: 0.6182 - my_iou_metric: 0.45 - ETA: 2:45:26 - loss: 0.6143 - my_iou_metric: 0.45 - ETA: 2:45:17 - loss: 0.6167 - my_iou_metric: 0.45 - ETA: 2:44:38 - loss: 0.6120 - my_iou_metric: 0.45 - ETA: 2:44:14 - loss: 0.6189 - my_iou_metric: 0.45 - ETA: 2:44:00 - loss: 0.6137 - my_iou_metric: 0.46 - ETA: 2:44:27 - loss: 0.6073 - my_iou_metric: 0.46 - ETA: 2:44:17 - loss: 0.6076 - my_iou_metric: 0.46 - ETA: 2:44:07 - loss: 0.6094 - my_iou_metric: 0.46 - ETA: 2:44:12 - loss: 0.6094 - my_iou_metric: 0.46 - ETA: 2:44:11 - loss: 0.6044 - my_iou_metric: 0.46 - ETA: 2:43:51 - loss: 0.6009 - my_iou_metric: 0.46 - ETA: 2:43:21 - loss: 0.5964 - my_iou_metric: 0.46 - ETA: 2:43:04 - loss: 0.5953 - my_iou_metric: 0.46 - ETA: 2:42:21 - loss: 0.5891 - my_iou_metric: 0.47 - ETA: 2:41:27 - loss: 0.5872 - my_iou_metric: 0.47 - ETA: 2:40:31 - loss: 0.5846 - my_iou_metric: 0.47 - ETA: 2:40:17 - loss: 0.5864 - my_iou_metric: 0.47 - ETA: 2:38:49 - loss: 0.5885 - my_iou_metric: 0.47 - ETA: 2:37:21 - loss: 0.5838 - my_iou_metric: 0.47 - ETA: 2:35:45 - loss: 0.5845 - my_iou_metric: 0.47 - ETA: 2:34:13 - loss: 0.5936 - my_iou_metric: 0.47 - ETA: 2:32:47 - loss: 0.5913 - my_iou_metric: 0.47 - ETA: 2:31:18 - loss: 0.5948 - my_iou_metric: 0.46 - ETA: 2:30:02 - loss: 0.6008 - my_iou_metric: 0.46 - ETA: 2:29:03 - loss: 0.6084 - my_iou_metric: 0.46 - ETA: 2:27:48 - loss: 0.6074 - my_iou_metric: 0.46 - ETA: 2:27:58 - loss: 0.6049 - my_iou_metric: 0.46 - ETA: 2:26:30 - loss: 0.6046 - my_iou_metric: 0.46 - ETA: 2:25:04 - loss: 0.6057 - my_iou_metric: 0.46 - ETA: 2:23:37 - loss: 0.6045 - my_iou_metric: 0.46 - ETA: 2:22:15 - loss: 0.6067 - my_iou_metric: 0.46 - ETA: 2:21:48 - loss: 0.6043 - my_iou_metric: 0.46 - ETA: 2:21:27 - loss: 0.6088 - my_iou_metric: 0.46 - ETA: 2:20:23 - loss: 0.6125 - my_iou_metric: 0.46 - ETA: 2:19:25 - loss: 0.6137 - my_iou_metric: 0.45 - ETA: 2:18:23 - loss: 0.6100 - my_iou_metric: 0.46 - ETA: 2:17:19 - loss: 0.6070 - my_iou_metric: 0.46 - ETA: 2:16:10 - loss: 0.6107 - my_iou_metric: 0.46 - ETA: 2:15:04 - loss: 0.6079 - my_iou_metric: 0.46 - ETA: 2:14:04 - loss: 0.6095 - my_iou_metric: 0.46 - ETA: 2:13:07 - loss: 0.6120 - my_iou_metric: 0.46 - ETA: 2:12:06 - loss: 0.6081 - my_iou_metric: 0.46 - ETA: 2:11:09 - loss: 0.6065 - my_iou_metric: 0.46 - ETA: 2:09:54 - loss: 0.6049 - my_iou_metric: 0.46 - ETA: 2:08:37 - loss: 0.6058 - my_iou_metric: 0.46 - ETA: 2:07:23 - loss: 0.6045 - my_iou_metric: 0.46 - ETA: 2:06:03 - loss: 0.6019 - my_iou_metric: 0.46 - ETA: 2:04:56 - loss: 0.6014 - my_iou_metric: 0.46 - ETA: 2:04:05 - loss: 0.6013 - my_iou_metric: 0.46 - ETA: 2:03:05 - loss: 0.5986 - my_iou_metric: 0.46 - ETA: 2:02:06 - loss: 0.6012 - my_iou_metric: 0.46 - ETA: 2:01:02 - loss: 0.6002 - my_iou_metric: 0.46 - ETA: 2:00:05 - loss: 0.5992 - my_iou_metric: 0.46 - ETA: 1:59:07 - loss: 0.5971 - my_iou_metric: 0.46 - ETA: 1:58:19 - loss: 0.6026 - my_iou_metric: 0.46 - ETA: 1:57:15 - loss: 0.6038 - my_iou_metric: 0.46 - ETA: 1:56:07 - loss: 0.6077 - my_iou_metric: 0.46 - ETA: 1:55:02 - loss: 0.6097 - my_iou_metric: 0.45 - ETA: 1:53:33 - loss: 0.6092 - my_iou_metric: 0.45 - ETA: 1:52:01 - loss: 0.6088 - my_iou_metric: 0.45 - ETA: 1:50:23 - loss: 0.6107 - my_iou_metric: 0.45 - ETA: 1:48:47 - loss: 0.6087 - my_iou_metric: 0.45 - ETA: 1:47:11 - loss: 0.6089 - my_iou_metric: 0.45 - ETA: 1:45:36 - loss: 0.6087 - my_iou_metric: 0.45 - ETA: 1:44:03 - loss: 0.6077 - my_iou_metric: 0.45 - ETA: 1:42:31 - loss: 0.6147 - my_iou_metric: 0.45 - ETA: 1:41:02 - loss: 0.6131 - my_iou_metric: 0.45 - ETA: 1:39:32 - loss: 0.6148 - my_iou_metric: 0.45 - ETA: 1:38:04 - loss: 0.6188 - my_iou_metric: 0.45 - ETA: 1:36:36 - loss: 0.6200 - my_iou_metric: 0.45 - ETA: 1:35:12 - loss: 0.6182 - my_iou_metric: 0.46 - ETA: 1:33:48 - loss: 0.6206 - my_iou_metric: 0.45 - ETA: 1:32:27 - loss: 0.6212 - my_iou_metric: 0.46 - ETA: 1:31:06 - loss: 0.6198 - my_iou_metric: 0.46 - ETA: 1:29:44 - loss: 0.6181 - my_iou_metric: 0.46 - ETA: 1:28:22 - loss: 0.6170 - my_iou_metric: 0.46 - ETA: 1:27:01 - loss: 0.6164 - my_iou_metric: 0.46 - ETA: 1:25:42 - loss: 0.6150 - my_iou_metric: 0.46 - ETA: 1:24:23 - loss: 0.6177 - my_iou_metric: 0.46 - ETA: 1:23:04 - loss: 0.6201 - my_iou_metric: 0.46 - ETA: 1:22:02 - loss: 0.6214 - my_iou_metric: 0.46 - ETA: 1:20:49 - loss: 0.6224 - my_iou_metric: 0.46 - ETA: 1:19:29 - loss: 0.6203 - my_iou_metric: 0.46 - ETA: 1:18:08 - loss: 0.6213 - my_iou_metric: 0.46 - ETA: 1:16:49 - loss: 0.6204 - my_iou_metric: 0.46 - ETA: 1:15:36 - loss: 0.6190 - my_iou_metric: 0.46 - ETA: 1:14:24 - loss: 0.6202 - my_iou_metric: 0.46 - ETA: 1:13:13 - loss: 0.6198 - my_iou_metric: 0.46 - ETA: 1:12:01 - loss: 0.6181 - my_iou_metric: 0.46 - ETA: 1:10:51 - loss: 0.6181 - my_iou_metric: 0.46 - ETA: 1:09:48 - loss: 0.6166 - my_iou_metric: 0.46 - ETA: 1:08:41 - loss: 0.6164 - my_iou_metric: 0.46 - ETA: 1:07:35 - loss: 0.6143 - my_iou_metric: 0.46 - ETA: 1:06:34 - loss: 0.6139 - my_iou_metric: 0.46 - ETA: 1:05:31 - loss: 0.6124 - my_iou_metric: 0.46 - ETA: 1:04:27 - loss: 0.6117 - my_iou_metric: 0.46 - ETA: 1:03:24 - loss: 0.6110 - my_iou_metric: 0.46 - ETA: 1:02:16 - loss: 0.6087 - my_iou_metric: 0.46 - ETA: 1:01:04 - loss: 0.6070 - my_iou_metric: 0.46 - ETA: 59:46 - loss: 0.6056 - my_iou_metric: 0.4690 - ETA: 58:25 - loss: 0.6049 - my_iou_metric: 0.46 - ETA: 57:04 - loss: 0.6055 - my_iou_metric: 0.47 - ETA: 55:43 - loss: 0.6058 - my_iou_metric: 0.47 - ETA: 54:23 - loss: 0.6033 - my_iou_metric: 0.47 - ETA: 53:05 - loss: 0.6021 - my_iou_metric: 0.47 - ETA: 51:48 - loss: 0.6036 - my_iou_metric: 0.47 - ETA: 50:32 - loss: 0.6068 - my_iou_metric: 0.47 - ETA: 49:17 - loss: 0.6057 - my_iou_metric: 0.47 - ETA: 48:01 - loss: 0.6055 - my_iou_metric: 0.4723"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3196/3196 [==============================] - ETA: 46:46 - loss: 0.6040 - my_iou_metric: 0.47 - ETA: 45:31 - loss: 0.6022 - my_iou_metric: 0.47 - ETA: 44:17 - loss: 0.6026 - my_iou_metric: 0.47 - ETA: 43:03 - loss: 0.6023 - my_iou_metric: 0.47 - ETA: 41:47 - loss: 0.6004 - my_iou_metric: 0.47 - ETA: 40:32 - loss: 0.5982 - my_iou_metric: 0.47 - ETA: 39:17 - loss: 0.5979 - my_iou_metric: 0.47 - ETA: 38:02 - loss: 0.5967 - my_iou_metric: 0.48 - ETA: 36:48 - loss: 0.5967 - my_iou_metric: 0.48 - ETA: 35:34 - loss: 0.5970 - my_iou_metric: 0.48 - ETA: 34:22 - loss: 0.5972 - my_iou_metric: 0.48 - ETA: 33:11 - loss: 0.5963 - my_iou_metric: 0.48 - ETA: 32:00 - loss: 0.5947 - my_iou_metric: 0.48 - ETA: 30:49 - loss: 0.5954 - my_iou_metric: 0.48 - ETA: 29:39 - loss: 0.5936 - my_iou_metric: 0.48 - ETA: 28:29 - loss: 0.5931 - my_iou_metric: 0.48 - ETA: 27:19 - loss: 0.5918 - my_iou_metric: 0.48 - ETA: 26:09 - loss: 0.5919 - my_iou_metric: 0.48 - ETA: 25:01 - loss: 0.5912 - my_iou_metric: 0.48 - ETA: 23:52 - loss: 0.5910 - my_iou_metric: 0.48 - ETA: 22:44 - loss: 0.5905 - my_iou_metric: 0.48 - ETA: 21:36 - loss: 0.5901 - my_iou_metric: 0.48 - ETA: 20:29 - loss: 0.5902 - my_iou_metric: 0.48 - ETA: 19:22 - loss: 0.5915 - my_iou_metric: 0.48 - ETA: 18:15 - loss: 0.5902 - my_iou_metric: 0.48 - ETA: 17:09 - loss: 0.5894 - my_iou_metric: 0.48 - ETA: 16:02 - loss: 0.5887 - my_iou_metric: 0.48 - ETA: 14:56 - loss: 0.5881 - my_iou_metric: 0.48 - ETA: 13:49 - loss: 0.5886 - my_iou_metric: 0.48 - ETA: 12:43 - loss: 0.5892 - my_iou_metric: 0.48 - ETA: 11:38 - loss: 0.5878 - my_iou_metric: 0.48 - ETA: 10:33 - loss: 0.5876 - my_iou_metric: 0.48 - ETA: 9:28 - loss: 0.5881 - my_iou_metric: 0.4827 - ETA: 8:23 - loss: 0.5875 - my_iou_metric: 0.481 - ETA: 7:17 - loss: 0.5896 - my_iou_metric: 0.481 - ETA: 6:12 - loss: 0.5889 - my_iou_metric: 0.480 - ETA: 5:06 - loss: 0.5880 - my_iou_metric: 0.480 - ETA: 4:02 - loss: 0.5871 - my_iou_metric: 0.481 - ETA: 2:57 - loss: 0.5851 - my_iou_metric: 0.482 - ETA: 1:52 - loss: 0.5841 - my_iou_metric: 0.482 - ETA: 48s - loss: 0.5850 - my_iou_metric: 0.481 - 13627s 4s/step - loss: 0.5860 - my_iou_metric: 0.4810 - val_loss: 1.7142 - val_my_iou_metric: 0.0830\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.00000 to 0.08297, saving model to unet_resnet.h5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_resnet(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 2  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:08<00:00,  3.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.4550 at threshold: 0.200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.220945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.162925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.033706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.259328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.362562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.454975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.220945\n",
       "std     0.204939   0.162925\n",
       "min     0.200000   0.000995\n",
       "25%     0.370000   0.033706\n",
       "50%     0.540000   0.259328\n",
       "75%     0.710000   0.362562\n",
       "max     0.880000   0.454975"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2359f010948>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "\n",
    "- Pretrained models can be used for segmentation problems:\n",
    "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
    "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
    "    - You can experiment with selection of layers for feature extraction\n",
    "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
    "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
    "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
    "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
    "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
    "\n",
    "\n",
    "### Possible experiments:\n",
    "\n",
    "- Change type of decoder block in created segmentation model\n",
    "- Create your own decoder blocks\n",
    "- Train with other losses\n",
    "- Train longer\n",
    "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
    "- Try different ranges and intervals for threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】コードの書き換え"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19の学習・推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "base_model = VGG19(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_vgg19(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = VGG19(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('block1_conv2').output \n",
    "    encoder2 = base_model.get_layer('block2_conv2').output \n",
    "    encoder3 = base_model.get_layer('block3_conv4').output \n",
    "    encoder4 = base_model.get_layer('block4_conv4').output \n",
    "    encoder5 = base_model.get_layer('block5_conv4').output\n",
    "    encoder6 = base_model.get_layer('block5_pool').output\n",
    "    \n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder6, 'center', num_filters=512)\n",
    "    concat6 = concatenate([center, encoder6], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder5 = decoder_block(\n",
    "        concat6, 'decoder5', num_filters=512)\n",
    "    concat5 = concatenate([UpSampling2D()(decoder5), encoder5], axis=-1)\n",
    "\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=512)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=256)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=128)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "    \n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    output = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           center_activation[0][0]          \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_conv (Conv2D)          (None, 7, 7, 512)    4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_bn (BatchNormalization (None, 7, 7, 512)    2048        decoder5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_activation (PReLU)     (None, 7, 7, 512)    25088       decoder5_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 512)  0           decoder5_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1024) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 14, 14, 512)  4719104     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 14, 14, 512)  2048        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder4_activation (PReLU)     (None, 14, 14, 512)  100352      decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 512)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 1024) 0           up_sampling2d_2[0][0]            \n",
      "                                                                 block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 28, 28, 256)  2359552     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 28, 28, 256)  1024        decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 28, 28, 256)  200704      decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 256)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 512)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 56, 56, 128)  589952      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 56, 56, 128)  512         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 56, 56, 128)  401408      decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 128 0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 256 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 112, 112, 64) 147520      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 112, 112, 64) 256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 112, 112, 64) 802816      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 224, 224, 128 0           up_sampling2d_5[0][0]            \n",
      "                                                                 block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 38,125,505\n",
      "Trainable params: 38,121,473\n",
      "Non-trainable params: 4,032\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_vgg19(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_conv1 (Conv2D)         (None, 7, 7, 512)    4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_bn1 (BatchNormalizatio (None, 7, 7, 512)    2048        decoder5_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_activation1 (PReLU)    (None, 7, 7, 512)    25088       decoder5_bn1[0][0]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 512)    0           decoder5_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_conv2 (Conv2D)         (None, 7, 7, 256)    1179904     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_bn2 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder5_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_activation2 (PReLU)    (None, 7, 7, 256)    12544       decoder5_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 256)    0           decoder5_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_conv3 (Conv2D)         (None, 7, 7, 512)    1180160     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_bn3 (BatchNormalizatio (None, 7, 7, 512)    2048        decoder5_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_activation3 (PReLU)    (None, 7, 7, 512)    25088       decoder5_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 512)    0           decoder5_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 512)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 512)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1024) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 14, 14, 512)  4719104     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 14, 14, 512)  2048        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 14, 14, 512)  100352      decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 512)  0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 14, 14, 256)  1179904     dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 14, 14, 256)  1024        decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 14, 14, 256)  50176       decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 256)  0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 14, 14, 512)  1180160     dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 14, 14, 512)  2048        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 14, 14, 512)  100352      decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 512)  0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 512)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 1024) 0           up_sampling2d_2[0][0]            \n",
      "                                                                 block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 28, 28, 256)  2359552     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 28, 28, 256)  1024        decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 28, 28, 256)  200704      decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 256)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 28, 28, 128)  295040      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 28, 28, 128)  512         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 28, 28, 128)  100352      decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 128)  0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 28, 28, 256)  295168      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 28, 28, 256)  1024        decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 28, 28, 256)  200704      decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 256)  0           decoder3_activation3[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 256)  0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 256)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 512)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 56, 56, 128)  589952      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 56, 56, 128)  512         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 56, 56, 128)  401408      decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 128)  0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 56, 56, 64)   73792       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 56, 56, 64)   256         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 56, 56, 64)   200704      decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 64)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 56, 56, 128)  73856       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 56, 56, 128)  512         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 56, 56, 128)  401408      decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 128)  0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 128)  0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 128 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 256 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 112, 112, 64) 147520      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 112, 112, 32) 18464       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 112, 112, 32) 128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 112, 112, 32) 401408      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 112, 112, 32) 0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 112, 112, 64) 18496       dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 112, 112, 64) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 64) 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 224, 224, 128 0           up_sampling2d_5[0][0]            \n",
      "                                                                 block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_19[0][0]                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 224, 224, 32) 0           dropout_19[0][0]                 \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 50,743,505\n",
      "Trainable params: 50,733,425\n",
      "Non-trainable params: 10,080\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 3196 samples, validate on 804 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2512/3196 [======================>.......] - ETA: 2:44:09 - loss: 1.4662 - my_iou_metric: 0.0000e+ - ETA: 2:42:46 - loss: 1.3410 - my_iou_metric: 0.0000e+ - ETA: 2:38:01 - loss: 1.3045 - my_iou_metric: 0.0021   - ETA: 2:37:58 - loss: 1.2777 - my_iou_metric: 0.01 - ETA: 2:39:12 - loss: 1.2687 - my_iou_metric: 0.03 - ETA: 2:39:13 - loss: 1.2179 - my_iou_metric: 0.05 - ETA: 2:38:00 - loss: 1.1974 - my_iou_metric: 0.05 - ETA: 2:36:20 - loss: 1.1665 - my_iou_metric: 0.07 - ETA: 2:35:32 - loss: 1.1615 - my_iou_metric: 0.07 - ETA: 2:34:16 - loss: 1.1465 - my_iou_metric: 0.08 - ETA: 2:34:46 - loss: 1.1488 - my_iou_metric: 0.08 - ETA: 2:36:32 - loss: 1.1766 - my_iou_metric: 0.07 - ETA: 2:37:16 - loss: 1.1537 - my_iou_metric: 0.07 - ETA: 2:37:25 - loss: 1.1316 - my_iou_metric: 0.08 - ETA: 2:36:34 - loss: 1.1238 - my_iou_metric: 0.08 - ETA: 2:37:23 - loss: 1.1321 - my_iou_metric: 0.07 - ETA: 2:39:08 - loss: 1.1217 - my_iou_metric: 0.07 - ETA: 2:39:11 - loss: 1.1151 - my_iou_metric: 0.07 - ETA: 2:38:53 - loss: 1.1127 - my_iou_metric: 0.08 - ETA: 2:38:25 - loss: 1.1072 - my_iou_metric: 0.08 - ETA: 2:38:01 - loss: 1.0977 - my_iou_metric: 0.08 - ETA: 2:37:22 - loss: 1.0969 - my_iou_metric: 0.07 - ETA: 2:37:25 - loss: 1.0903 - my_iou_metric: 0.07 - ETA: 2:37:05 - loss: 1.0964 - my_iou_metric: 0.07 - ETA: 2:36:24 - loss: 1.0910 - my_iou_metric: 0.07 - ETA: 2:35:27 - loss: 1.0822 - my_iou_metric: 0.08 - ETA: 2:34:21 - loss: 1.0769 - my_iou_metric: 0.08 - ETA: 2:33:06 - loss: 1.0763 - my_iou_metric: 0.08 - ETA: 2:31:55 - loss: 1.0660 - my_iou_metric: 0.08 - ETA: 2:30:57 - loss: 1.0591 - my_iou_metric: 0.08 - ETA: 2:29:53 - loss: 1.0558 - my_iou_metric: 0.08 - ETA: 2:28:51 - loss: 1.0509 - my_iou_metric: 0.08 - ETA: 2:28:01 - loss: 1.0605 - my_iou_metric: 0.08 - ETA: 2:27:22 - loss: 1.0544 - my_iou_metric: 0.08 - ETA: 2:26:29 - loss: 1.0495 - my_iou_metric: 0.08 - ETA: 2:25:29 - loss: 1.0494 - my_iou_metric: 0.08 - ETA: 2:24:37 - loss: 1.0450 - my_iou_metric: 0.09 - ETA: 2:23:42 - loss: 1.0458 - my_iou_metric: 0.09 - ETA: 2:22:56 - loss: 1.0415 - my_iou_metric: 0.09 - ETA: 2:22:07 - loss: 1.0374 - my_iou_metric: 0.09 - ETA: 2:21:26 - loss: 1.0308 - my_iou_metric: 0.09 - ETA: 2:20:45 - loss: 1.0290 - my_iou_metric: 0.09 - ETA: 2:20:05 - loss: 1.0223 - my_iou_metric: 0.09 - ETA: 2:19:20 - loss: 1.0205 - my_iou_metric: 0.09 - ETA: 2:18:38 - loss: 1.0148 - my_iou_metric: 0.10 - ETA: 2:18:28 - loss: 1.0069 - my_iou_metric: 0.10 - ETA: 2:17:54 - loss: 1.0042 - my_iou_metric: 0.10 - ETA: 2:17:22 - loss: 1.0003 - my_iou_metric: 0.10 - ETA: 2:16:44 - loss: 0.9929 - my_iou_metric: 0.10 - ETA: 2:15:52 - loss: 0.9981 - my_iou_metric: 0.10 - ETA: 2:14:55 - loss: 0.9964 - my_iou_metric: 0.10 - ETA: 2:14:13 - loss: 0.9967 - my_iou_metric: 0.10 - ETA: 2:13:24 - loss: 0.9994 - my_iou_metric: 0.10 - ETA: 2:12:26 - loss: 1.0007 - my_iou_metric: 0.10 - ETA: 2:11:30 - loss: 0.9959 - my_iou_metric: 0.10 - ETA: 2:10:40 - loss: 0.9936 - my_iou_metric: 0.10 - ETA: 2:09:44 - loss: 0.9900 - my_iou_metric: 0.10 - ETA: 2:08:46 - loss: 0.9885 - my_iou_metric: 0.10 - ETA: 2:07:47 - loss: 0.9893 - my_iou_metric: 0.10 - ETA: 2:07:00 - loss: 0.9860 - my_iou_metric: 0.10 - ETA: 2:06:13 - loss: 0.9881 - my_iou_metric: 0.10 - ETA: 2:05:45 - loss: 0.9824 - my_iou_metric: 0.10 - ETA: 2:04:58 - loss: 0.9818 - my_iou_metric: 0.10 - ETA: 2:04:07 - loss: 0.9761 - my_iou_metric: 0.10 - ETA: 2:03:17 - loss: 0.9736 - my_iou_metric: 0.10 - ETA: 2:02:28 - loss: 0.9819 - my_iou_metric: 0.10 - ETA: 2:01:36 - loss: 0.9798 - my_iou_metric: 0.10 - ETA: 2:00:41 - loss: 0.9807 - my_iou_metric: 0.10 - ETA: 1:59:40 - loss: 0.9812 - my_iou_metric: 0.10 - ETA: 1:58:40 - loss: 0.9803 - my_iou_metric: 0.10 - ETA: 1:57:42 - loss: 0.9875 - my_iou_metric: 0.10 - ETA: 1:56:41 - loss: 0.9835 - my_iou_metric: 0.10 - ETA: 1:55:43 - loss: 0.9791 - my_iou_metric: 0.11 - ETA: 1:54:53 - loss: 0.9770 - my_iou_metric: 0.11 - ETA: 1:53:59 - loss: 0.9734 - my_iou_metric: 0.11 - ETA: 1:53:04 - loss: 0.9676 - my_iou_metric: 0.11 - ETA: 1:52:08 - loss: 0.9674 - my_iou_metric: 0.11 - ETA: 1:51:13 - loss: 0.9656 - my_iou_metric: 0.11 - ETA: 1:50:17 - loss: 0.9624 - my_iou_metric: 0.11 - ETA: 1:49:21 - loss: 0.9635 - my_iou_metric: 0.11 - ETA: 1:48:25 - loss: 0.9595 - my_iou_metric: 0.11 - ETA: 1:47:28 - loss: 0.9543 - my_iou_metric: 0.11 - ETA: 1:46:32 - loss: 0.9514 - my_iou_metric: 0.11 - ETA: 1:45:37 - loss: 0.9477 - my_iou_metric: 0.11 - ETA: 1:45:03 - loss: 0.9489 - my_iou_metric: 0.11 - ETA: 1:44:16 - loss: 0.9531 - my_iou_metric: 0.11 - ETA: 1:43:36 - loss: 0.9490 - my_iou_metric: 0.11 - ETA: 1:42:59 - loss: 0.9466 - my_iou_metric: 0.11 - ETA: 1:42:46 - loss: 0.9464 - my_iou_metric: 0.11 - ETA: 1:42:29 - loss: 0.9477 - my_iou_metric: 0.11 - ETA: 1:42:09 - loss: 0.9485 - my_iou_metric: 0.11 - ETA: 1:41:46 - loss: 0.9512 - my_iou_metric: 0.11 - ETA: 1:41:21 - loss: 0.9521 - my_iou_metric: 0.11 - ETA: 1:41:02 - loss: 0.9499 - my_iou_metric: 0.11 - ETA: 1:40:38 - loss: 0.9487 - my_iou_metric: 0.11 - ETA: 1:40:13 - loss: 0.9459 - my_iou_metric: 0.11 - ETA: 1:39:44 - loss: 0.9473 - my_iou_metric: 0.11 - ETA: 1:39:18 - loss: 0.9459 - my_iou_metric: 0.11 - ETA: 1:38:44 - loss: 0.9473 - my_iou_metric: 0.11 - ETA: 1:38:09 - loss: 0.9485 - my_iou_metric: 0.11 - ETA: 1:37:32 - loss: 0.9459 - my_iou_metric: 0.11 - ETA: 1:36:52 - loss: 0.9434 - my_iou_metric: 0.11 - ETA: 1:36:13 - loss: 0.9439 - my_iou_metric: 0.11 - ETA: 1:35:34 - loss: 0.9442 - my_iou_metric: 0.11 - ETA: 1:34:54 - loss: 0.9422 - my_iou_metric: 0.11 - ETA: 1:34:11 - loss: 0.9414 - my_iou_metric: 0.11 - ETA: 1:33:30 - loss: 0.9383 - my_iou_metric: 0.11 - ETA: 1:32:49 - loss: 0.9381 - my_iou_metric: 0.11 - ETA: 1:32:11 - loss: 0.9348 - my_iou_metric: 0.12 - ETA: 1:31:28 - loss: 0.9328 - my_iou_metric: 0.12 - ETA: 1:30:41 - loss: 0.9330 - my_iou_metric: 0.12 - ETA: 1:29:54 - loss: 0.9300 - my_iou_metric: 0.12 - ETA: 1:29:06 - loss: 0.9273 - my_iou_metric: 0.12 - ETA: 1:28:19 - loss: 0.9251 - my_iou_metric: 0.12 - ETA: 1:27:33 - loss: 0.9255 - my_iou_metric: 0.12 - ETA: 1:26:47 - loss: 0.9252 - my_iou_metric: 0.12 - ETA: 1:25:59 - loss: 0.9265 - my_iou_metric: 0.12 - ETA: 1:25:11 - loss: 0.9242 - my_iou_metric: 0.12 - ETA: 1:24:21 - loss: 0.9262 - my_iou_metric: 0.12 - ETA: 1:23:32 - loss: 0.9247 - my_iou_metric: 0.12 - ETA: 1:22:42 - loss: 0.9225 - my_iou_metric: 0.12 - ETA: 1:21:51 - loss: 0.9207 - my_iou_metric: 0.12 - ETA: 1:21:00 - loss: 0.9193 - my_iou_metric: 0.12 - ETA: 1:20:08 - loss: 0.9176 - my_iou_metric: 0.12 - ETA: 1:19:16 - loss: 0.9184 - my_iou_metric: 0.12 - ETA: 1:18:23 - loss: 0.9201 - my_iou_metric: 0.12 - ETA: 1:17:29 - loss: 0.9209 - my_iou_metric: 0.12 - ETA: 1:16:35 - loss: 0.9201 - my_iou_metric: 0.12 - ETA: 1:15:41 - loss: 0.9191 - my_iou_metric: 0.12 - ETA: 1:14:46 - loss: 0.9174 - my_iou_metric: 0.12 - ETA: 1:38:16 - loss: 0.9173 - my_iou_metric: 0.12 - ETA: 1:36:50 - loss: 0.9178 - my_iou_metric: 0.12 - ETA: 1:35:23 - loss: 0.9175 - my_iou_metric: 0.12 - ETA: 1:33:56 - loss: 0.9167 - my_iou_metric: 0.12 - ETA: 1:32:29 - loss: 0.9172 - my_iou_metric: 0.12 - ETA: 1:31:02 - loss: 0.9162 - my_iou_metric: 0.12 - ETA: 1:29:35 - loss: 0.9144 - my_iou_metric: 0.12 - ETA: 1:28:08 - loss: 0.9137 - my_iou_metric: 0.12 - ETA: 1:26:41 - loss: 0.9111 - my_iou_metric: 0.12 - ETA: 1:25:17 - loss: 0.9129 - my_iou_metric: 0.12 - ETA: 1:23:51 - loss: 0.9122 - my_iou_metric: 0.12 - ETA: 1:22:24 - loss: 0.9105 - my_iou_metric: 0.12 - ETA: 1:20:57 - loss: 0.9081 - my_iou_metric: 0.12 - ETA: 1:19:30 - loss: 0.9115 - my_iou_metric: 0.12 - ETA: 1:18:04 - loss: 0.9097 - my_iou_metric: 0.12 - ETA: 1:16:37 - loss: 0.9105 - my_iou_metric: 0.12 - ETA: 1:15:11 - loss: 0.9080 - my_iou_metric: 0.12 - ETA: 1:13:44 - loss: 0.9091 - my_iou_metric: 0.12 - ETA: 1:12:19 - loss: 0.9075 - my_iou_metric: 0.12 - ETA: 1:10:53 - loss: 0.9081 - my_iou_metric: 0.12 - ETA: 1:09:27 - loss: 0.9075 - my_iou_metric: 0.12 - ETA: 1:08:00 - loss: 0.9061 - my_iou_metric: 0.12 - ETA: 1:09:53 - loss: 0.9068 - my_iou_metric: 0.12 - ETA: 1:08:21 - loss: 0.9063 - my_iou_metric: 0.12 - ETA: 1:06:49 - loss: 0.9043 - my_iou_metric: 0.12 - ETA: 1:05:16 - loss: 0.9027 - my_iou_metric: 0.12 - ETA: 1:03:43 - loss: 0.9019 - my_iou_metric: 0.1286"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3196/3196 [==============================] - ETA: 1:02:11 - loss: 0.9012 - my_iou_metric: 0.12 - ETA: 1:00:40 - loss: 0.9033 - my_iou_metric: 0.12 - ETA: 59:09 - loss: 0.9022 - my_iou_metric: 0.1292 - ETA: 57:39 - loss: 0.9024 - my_iou_metric: 0.12 - ETA: 56:08 - loss: 0.9025 - my_iou_metric: 0.12 - ETA: 54:37 - loss: 0.9021 - my_iou_metric: 0.13 - ETA: 53:06 - loss: 0.9067 - my_iou_metric: 0.13 - ETA: 51:35 - loss: 0.9078 - my_iou_metric: 0.13 - ETA: 50:06 - loss: 0.9072 - my_iou_metric: 0.13 - ETA: 48:36 - loss: 0.9072 - my_iou_metric: 0.13 - ETA: 47:06 - loss: 0.9069 - my_iou_metric: 0.13 - ETA: 45:36 - loss: 0.9066 - my_iou_metric: 0.13 - ETA: 44:06 - loss: 0.9060 - my_iou_metric: 0.13 - ETA: 42:36 - loss: 0.9055 - my_iou_metric: 0.13 - ETA: 41:06 - loss: 0.9042 - my_iou_metric: 0.13 - ETA: 39:33 - loss: 0.9044 - my_iou_metric: 0.13 - ETA: 37:58 - loss: 0.9035 - my_iou_metric: 0.13 - ETA: 36:26 - loss: 0.9019 - my_iou_metric: 0.13 - ETA: 34:56 - loss: 0.9029 - my_iou_metric: 0.13 - ETA: 33:25 - loss: 0.9045 - my_iou_metric: 0.13 - ETA: 31:55 - loss: 0.9046 - my_iou_metric: 0.13 - ETA: 30:23 - loss: 0.9051 - my_iou_metric: 0.13 - ETA: 28:52 - loss: 0.9050 - my_iou_metric: 0.13 - ETA: 27:21 - loss: 0.9056 - my_iou_metric: 0.13 - ETA: 25:50 - loss: 0.9084 - my_iou_metric: 0.13 - ETA: 25:51 - loss: 0.9094 - my_iou_metric: 0.13 - ETA: 24:14 - loss: 0.9094 - my_iou_metric: 0.13 - ETA: 22:40 - loss: 0.9093 - my_iou_metric: 0.13 - ETA: 21:06 - loss: 0.9087 - my_iou_metric: 0.13 - ETA: 19:33 - loss: 0.9092 - my_iou_metric: 0.13 - ETA: 17:59 - loss: 0.9103 - my_iou_metric: 0.13 - ETA: 16:25 - loss: 0.9106 - my_iou_metric: 0.13 - ETA: 14:52 - loss: 0.9092 - my_iou_metric: 0.13 - ETA: 13:19 - loss: 0.9085 - my_iou_metric: 0.13 - ETA: 11:46 - loss: 0.9085 - my_iou_metric: 0.13 - ETA: 10:14 - loss: 0.9089 - my_iou_metric: 0.13 - ETA: 8:42 - loss: 0.9089 - my_iou_metric: 0.1313 - ETA: 7:10 - loss: 0.9089 - my_iou_metric: 0.131 - ETA: 5:39 - loss: 0.9077 - my_iou_metric: 0.131 - ETA: 4:08 - loss: 0.9084 - my_iou_metric: 0.131 - ETA: 2:37 - loss: 0.9077 - my_iou_metric: 0.131 - ETA: 1:07 - loss: 0.9078 - my_iou_metric: 0.131 - 18751s 6s/step - loss: 0.9086 - my_iou_metric: 0.1316 - val_loss: 1.4799 - val_my_iou_metric: 0.1789\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.17892, saving model to unet_resnet.h5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_vgg19(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 1  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:54<00:00,  1.55s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.3807 at threshold: 0.200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.263369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.056984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.176244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.218284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.253234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.306095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.380721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.263369\n",
       "std     0.204939   0.056984\n",
       "min     0.200000   0.176244\n",
       "25%     0.370000   0.218284\n",
       "50%     0.540000   0.253234\n",
       "75%     0.710000   0.306095\n",
       "max     0.880000   0.380721"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e19b5a85c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNetはBest IoU: 0.4550 at threshold: 0.200\n",
    "## VGG19はBest IoU: 0.3807 at threshold: 0.200であった。\n",
    "## どちらもthresholdが0.2の時にIoUが最も高かったので、学習不足が考えられる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
