{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) 物体検出の分野にはどういった手法が存在したか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Although region-based CNNs were computationally expensive as originally developed in [5], their cost has been drastically reduced thanks to sharing convolutions across proposals [1], [2]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-CNN、fast-CNN、SPPnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以下参考文献[5]:Rich feature hierarchies for accurate object detection and semantic segmentation\n",
    "## Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. \n",
    "\n",
    "## 画像の中の物体を局在化して分けるために、高容量のCNNを提案領域に適応させる。ラベル付けされたトレーニングデータが少ない場合、補助タスクで教師付き事前トレーニングを行い、その後に領域固有の微調整を行う\n",
    "\n",
    "## Object detection system overview. Our system (1) takes an input image, (2) extracts around 2000 bottom-up region proposals, (3) computes features for each proposal using a large convolutional neural network (CNN), and then (4) classifies each region using class-specific linear SVMs. R-CNN achieves a mean average precision (mAP) of 53.7% on PASCAL VOC 2010.\n",
    "\n",
    "## 画像の中で物体が映っていると予測される領域を予測値として出し、それをCNNに渡すことで特徴量を作成し、SVMで分類する\n",
    "\n",
    "## 領域提案にはSelective Searchを使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Fasterとあるが、どういった仕組みで高速化したのか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this paper, we show that an algorithmic change— computing proposals with a deep convolutional neural network—leads to an elegant and effective solution where proposal computation is nearly cost-free given the detection network’s computation. To this end, we introduce novel Region Proposal Networks (RPNs) that share convolutional layers with state-of-the-art object detection networks [1], [2]. By sharing convolutions at test-time, the marginal cost for computing proposals is small (e.g., 10ms per image).\n",
    "\n",
    "## 領域提案の手法をselective serachからrpnに変更することで最初から最後までニューラルネットワークになり、学習を一気に行うことができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) One-Stageの手法とTwo-Stageの手法はどう違うのか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The OverFeat paper [9] proposes a detection method that uses regressors and classifiers on sliding windows over convolutional feature maps. OverFeat is a one-stage, class-specific detection pipeline, and ours is a two-stage cascade consisting of class-agnostic proposals and class-specific detections.\n",
    "\n",
    "## One-stageはクラスに固有の検出パイプラインであるが、Two-stageはクラスに依存しない提案とクラスに固有の検出の2段階のカスケードである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) RPNとは何か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Region Proposal Network (RPN) takes an image (of any size) as input and outputs a set of rectangular object proposals\n",
    "\n",
    "## 領域提案する手法。任意のサイズの特徴量マップを受け取って、9種類のアンカーを使って物体か背景かの2値分類のスコアと、矩形の中心座標と幅と高さの4種の値を出力として出す。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5) RoIプーリングとは何か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以下参考文献[2] R. Girshick, “Fast R-CNN,” in IEEE International Conference on Computer Vision (ICCV), 2015.\n",
    "\n",
    "## The RoI pooling layer uses max pooling to convert the features inside any valid region of interest into a small feature map with a fixed spatial extent of H × W (e.g., 7 × 7), where H and W are layer hyper-parameters that are independent of any particular RoI. In this paper, an RoI is a rectangular window into a conv feature map. Each RoI is defined by a four-tuple (r, c, h, w) that specifies its top-left corner (r, c) and its height and width (h, w).\n",
    "\n",
    "## 任意のサイズの領域をmaxプーリングして固定のサイズ（サイズはROIに依存しないハイパーパラメータ）を出力する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (6) Anchorのサイズはどうするのが適切か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For anchors, we use 3 scales with box areas of 1282 , 2562 , and 5122 pixels, and 3 aspect ratios of 1:1, 1:2, and 2:1. These hyper-parameters are not carefully chosen for a particular dataset, and we provide ablation experiments on their effects in the next section.\n",
    "\n",
    "## 128,256,512ピクセルの3つの大きさの四角の領域それぞれに1:1, 1:2, 2:1の3つのアスペクト比を使う（合計9個のanckorサイズ）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (7) 何というデータセットを使い、先行研究に比べどういった指標値が得られているか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 2: Detection results on PASCAL VOC 2007 test set (trained on VOC 2007 trainval). The detectors are Fast R-CNN with ZF, but using various proposal methods for training and testing.\n",
    "\n",
    "## n PASCAL VOC 2007というデータセットに対してSelective Searchを使用した先行研究ではmAPが58.7%であったのに対して、本研究では59.9%に向上した。\n",
    "\n",
    "## Table 3: Detection results on PASCAL VOC 2007 test set. The detector is Fast R-CNN and VGG-16. Training data: “07”: VOC 2007 trainval, “07+12”: union set of VOC 2007 trainval and VOC 2012 trainval. For RPN, the train-time proposals for Fast R-CNN are 2000. † : this number was reported in [2]; using the repository provided by this paper, this result is higher (68.1).\n",
    "\n",
    "## VOC2012をtrainデータとして増やすと先行研究ではmAPが70.0%であったのに対して、本研究では73.2%に向上した。\n",
    "\n",
    "## Table 5: Timing (ms) on a K40 GPU, except SS proposal is evaluated in a CPU. “Region-wise” includes NMS, pooling, fully-connected, and softmax layers. See our released code for the profiling of running time.\n",
    "\n",
    "## 処理速度が先行研究では0.5fpsであったのに対して、本研究では5fpsに向上した。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
